---
title: "Assignment 7"
author: "Francis Surroca"
date: '2022-08-03'
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages}
# Add any packages you want in this chunk:
library(plotly)
library(gamlr)

```

For this assignment, you are going to implement the LASSO regression covered in class.

You will need to reference your previous submission. We will use the previous data and your previous models.

# Use Data and model from Assignment06

Bring in the data and make sure the data types are correct. If not, make the proper changes. The file is located within this project. *data/prop_prices_reduced.csv*

```{r}
prop_prices <- read.csv("data\\prop_prices_reduced.csv")
head(prop_prices)
summary(prop_prices)

prop_prices$lake_front <- prop_prices$dist_lakes
prop_prices$lake_front[prop_prices$lake_front < 100] = 1
prop_prices$lake_front[prop_prices$lake_front > 100] = 0

prop_prices$downtown <- prop_prices$dist_cbd
prop_prices$downtown[prop_prices$downtown < 5280] = 1
prop_prices$downtown[prop_prices$downtown > 5280] = 0

prop_prices$luxury = 0
prop_prices$luxury[prop_prices$bed > 4 & prop_prices$area_heated > 2500 & prop_prices$pool == 1] = 1

normalized <- subset(prop_prices, prop_prices$sale_def < 1000000)

# Use only the most significant variables in the formula
fixed_reg = glm(sale_def ~ bed + area_heated + lake_front + luxury, data=normalized)
summary(fixed_reg) 
coef(fixed_reg) 
par(mfrow=c(2,2))
plot(fixed_reg)
par(mfrow=c(1,1))

```

# Seperate Data into Testing and Training

This time, I want you to separate your data into testing and training. For this exercise, randomly extract 100 for testing different models, and save the other 900 for training your models.

```{r}
sample_row_numbers <- sample(nrow(prop_prices), size=100)
testing_df <- prop_prices[sample_row_numbers, ]
training_df <- prop_prices[-sample_row_numbers, ]

```

# Run model

Run your final model you had in the previous assignment to the training data

```{r}
training_reg = glm(sale_def ~ bed + area_heated + lake_front + luxury, data=training_df)
summary(training_reg) 
coef(training_reg) 
par(mfrow=c(2,2))
plot(fixed_reg)
par(mfrow=c(1,1))

```

# LASSO

With the same model in part 2, run the standard LASSO regression model on the training data.

```{r}
training_response <- data.matrix(training_df$sale_def)
training_data_matrix <- data.matrix(training_df[ , c('bed','area_heated','lake_front','luxury')])
result <- gamlr(training_data_matrix, log(training_response), verb=TRUE)

summary(result)
coef(result)

plot(result) ## path plot
```

# 10-fold Cross-validation

Now using the same model in part 2, run a 10-fold cross-validated LASSO on the training data

```{r}
cv.result <- cv.gamlr(training_data_matrix, log(training_response), verb=TRUE,nfold =10)
beta1se <- coef(cv.result) ## 1se rule; see ?cv.gamlr
betamin <- coef(cv.result, select="min") ## min cv selection
# cbind(beta1se,betamin)[c("tvguide.com","americanexpress.com"),]

par(mfrow=c(1,2))
plot(cv.result)
plot(cv.result$gamlr) ## cv.gamlr includes a gamlr object
?gamlr


```

# Calculate RMSE for AIC, BIC, AICc, cv.min and cv.1se

Lastly, using the testing data, I want you to calculate the RMSE for each of the lambda's selection methods discussed (AIC, BIC, AICc, cv.min, cv.1se) and the the model in part 2. Which method performed the best in prediction the home price?

```{r}
ll <- log(result$lambda) ## the sequence of lambdas

log(result$lambda[which.min(AICc(result))])
log(result$lambda[which.min(AIC(result))])
log(result$lambda[which.min(BIC(result))])
log(cv.result$lambda.min)
log(cv.result$lambda.1se)

plot(result, col="grey")
abline(v=ll[which.min(AICc(result))], col="black", lty=2)
abline(v=ll[which.min(AIC(result))], col="orange", lty=2)
abline(v=ll[which.min(BIC(result))], col="green", lty=2)
abline(v=log(cv.result$lambda.min), col="blue", lty=2)
abline(v=log(cv.result$lambda.1se), col="purple", lty=2)
legend("topright", bty="n", lwd=1, 
	col=c("black","orange","green","blue","purple"),
	legend=c("AICc","AIC","BIC","CV.min","CV.1se"))
```

`Didn't calculate RMSE and determine which model performed the best (-20)`